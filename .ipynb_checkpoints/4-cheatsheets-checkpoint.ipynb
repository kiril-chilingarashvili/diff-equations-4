{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23157eee-549e-42c4-8fc4-c8bc4819f269",
   "metadata": {},
   "source": [
    "# Unit 4: Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80961915-3970-47b4-beaf-4addf201614f",
   "metadata": {},
   "source": [
    "### L11.2. Why convolution?\n",
    "\n",
    "### We have learned to determine the system response of LTI systems by using the Laplace transform to convert the problem to a simple algebraic relation in the frequency domain. This is effective, and this method reveals important features of the system response, especially about its long term behavior.\n",
    "\n",
    "### This method depends on the observation that the system function $H(s)$ is the Laplace transform of the unit impulse response (or “weight function\") $h(t)$. This implies that the Laplace transform of the system response (with rest initial conditions) to an input signal $f(t)$ is simply the product\n",
    "## $$ X(s) = H(s) F(s) $$\n",
    " \n",
    "### In this lecture we will analyze the relationship between the unit impulse response, the input signal, and the system response (with rest initial conditions) directly in the time domain. The result can be written as\n",
    "## $$ x(t) = h(t) * f(t) $$\n",
    " \n",
    "### where the asterisk denotes a new “product operation\" on signals, known as ***convolution***.\n",
    "\n",
    "### So one way to define convolution is by means of the Laplace transform:\n",
    "## $$ \\mathcal{L}(h(t) * f(t); s) = H(s) F(s) $$\n",
    " \n",
    "### Here $h(t)$ and $f(t)$ can be pretty much any pair of signals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4870676c-63ab-43fe-8469-192fbf462d13",
   "metadata": {},
   "source": [
    "## L11.3. Convolution.\n",
    "\n",
    "### The integral definition of convolution is\n",
    "## $$ f(t) * h(t) = \\int_{0}^{t} f(\\tau) h(t-\\tau) d\\tau $$\n",
    " \n",
    "### (Some motivation for this formula can be found on the last tab of this lecture.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bbc443-c902-46d6-bb74-3cc45209abaf",
   "metadata": {},
   "source": [
    "## L11.4. Farm run-off and convolution.\n",
    "\n",
    "### To repeat, convolution may also be defined as the following integral:\n",
    "## $$ f(t) * h(t)  \\int_{0}^{t} f(\\tau) h(t-\\tau) d\\tau $$\n",
    " \n",
    "### We confess that this formula is at first rather hard to understand. The following story may help elucidate it.\n",
    "\n",
    "### Phosphate fertilizer is applied seasonally to the ground in a certain farm. Some of the fertilizer runs off into a lake, where it undergoes natural decay (by chemical process or being carried away by an outflow from the lake).\n",
    "\n",
    "### We can model this situation as follows: Write $f(t)$ for the rate at which phosphate is entering the lake at time $t$ (in kg/year). Write $x(t)$ for the phosphate load in the lake (in kg). Write $a$ for the rate of natural decay of the phosphate in the lake. We then have a simple linear model for this system:\n",
    "## $$ \\dot{x} + ax = f(t) $$\n",
    " \n",
    "### The input signal is $f(t)$; the system response is $x(t)$. Suppose that at $t=0$ there is no phosphate in the lake at all; this is rest initial conditions.\n",
    "\n",
    "### Let's fix a moment in time, after the system has run for a while and try to evaluate $x$ at that instant. We will denote the fixed time we are looking at by $t$. This is dangerous notation, because we really want $t$ to be \"fixed\" for the moment. We will determine the amount of phosphate, $x(t)$, in the lake at time $t$ using the principle of superposition.\n",
    "\n",
    "### The phosphate added to the lake at each moment between time 0 and time $t$ makes a contribution to the value of $x(t)$. We need another symbol for these intermediate times; let's use the Greek letter $\\tau$.\n",
    "\n",
    "### Begin by thinking about the contribution to $x(t)$ made by the phosphate added to the lake right at the beginning – say between time $0$ and time $\\Delta \\tau$, where $\\Delta \\tau$ is very small. The amount of phosphate added in that time interval is close to $f(0) \\Delta \\tau$: the rate of deposition at time 0, times the amount of time elapsed. But not all this phosphate is still present at the later time $t$. It has decayed according to the natural decay process. So at time $t$ this first time interval contributes\n",
    "## $$ f(0) \\Delta \\tau \\cdot e^{-at} $$\n",
    " \n",
    "### kilograms to the value of $x(t)$.\n",
    "\n",
    "### Now think about a later small time interval, still between 0 and $t$; say between time $\\tau$ and time $\\tau + \\Delta \\tau$. The value of the input signal is $f(\\tau)$, so in this time interval some $f(\\tau)\\Delta \\tau$ kg is added to the lake. But not all of this is still present at the later time $t$. How much time has elapsed between time $\\tau$ and the later time $t$? Answer: $t-\\tau$. So the phosphate added around time $\\tau$ has been reduced by the factor $e^{-a(t-\\tau)}$; the contribution to the value $x(t)$ is\n",
    "## $$ f(\\tau) \\Delta \\tau \\cdot e^{-a(t-\\tau)} $$\n",
    " \n",
    "### kilograms.\n",
    "\n",
    "### The value $x(t)$ is the sum of these small contributions. For $\\Delta \\tau$ sufficiently small, this sum becomes indistinguishable from an integral; the only notational change is to replace $\\Delta \\tau$ by $d\\tau$ (and place it at the end of the product. The integral runs from $\\tau=0$ to $\\tau=t$:\n",
    "## $$ x(t) = \\int_{0}^{t} f(\\tau) e^{-a(t-\\tau)} $$\n",
    " \n",
    "### This is the ***convolution integral***.\n",
    "\n",
    "### We can recognize the function $e^{-a\\tau}$ as the unit impulse response for the differential operator in our system, $D+aI$:\n",
    "## $$ h(\\tau) = u(\\tau) e^{-a\\tau} $$\n",
    " \n",
    "### In the integral, $t>\\tau$, so we never evaluate $e^{-a\\tau}$ at negative values of $\\tau$, and so the step function $u(\\tau)$ has no impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac22db-6601-4e87-9dcd-b0731f56ba0d",
   "metadata": {},
   "source": [
    "### ***Mathlet and general statement***.\n",
    "\n",
    "### We hope this story helps to justify and explain the terms in the convolution integral. To visualize this process more clearly, please use the mathlet ***Convolution: Accumulation***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc4158b6-737c-4eb1-94a9-37ee1be379e6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"900\" height=\"650\" src=\"https://1803mathlets.netlify.app/convaccum\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>  \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe width=\"900\" height=\"650\" src=\"https://1803mathlets.netlify.app/convaccum\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70612ecd-0c28-4b3f-9ac3-5b51cd83159d",
   "metadata": {},
   "source": [
    "### Select as Signal $f(t) = 1 + \\cos(bt)$ and as weight function $g(t) = e^{-at}$. Recall that the weight function is the unit impulse response.\n",
    "\n",
    "### (The mathlet writes $g(t)$ for what we are writing $h(t)$. Also, it takes $a=\\ln(2)$ and $b=2$.)\n",
    "\n",
    "### This replicates the farm run-off scenario.\n",
    "\n",
    "### The lower window shows a graph of the input signal; you can see the seasonal variation in the rate of run-off.\n",
    "\n",
    "### Please click on the time slider at $t=3$. Then position the cursor in either window near the vertical line $t=3$. This is near to $t=\\pi$, which is the period of the oscillation, so the value of the input signal $f(t)$ there is about 2.\n",
    "\n",
    "### Now depress the mouse key. Blocks of color appear in both windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c418d09-e5f9-4c6c-8809-3fa619023c2a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/JbuG6u2ko_0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/JbuG6u2ko_0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db08e5b0-05e0-4976-a3b8-8cc62d5f6cfc",
   "metadata": {},
   "source": [
    "### ***Convolution process***\n",
    "\n",
    "### The process we described actually applies verbatim to any LTI system! The time invariance tells us that the system response to a delayed delta function is just the correspondingly delayed impulse response; and linearity lets us apply superposition to get the result. Let us restate the conclusion:\n",
    "\n",
    "### ***The system response (with rest initial conditions) by an LTI system to a signal $f(t)$ is given by convolving with the unit impulse response***:\n",
    "## $$ x(t) = f(t) * w(t) $$\n",
    " \n",
    "### ***Another perspective***.\n",
    "### The signal $f(t)$ can be written as an integral of scaled delta functions:\n",
    "## $$ f(t) = \\int_{0}^{t}f(\\tau) \\delta(t-\\tau) d\\tau $$\n",
    " \n",
    "### (Recall that $t$ is the variable, not $\\tau$.)\n",
    "\n",
    "### By the superposition principle, then, the system response (with rest initial conditions) is the corresponding integral of the system responses to the constituent signals, $f(\\tau) \\delta(t-\\tau) d\\tau$. If $h(t)$ is the system response to $\\delta(t)$, then, by time invariance, the system response to the delayed delta function $\\delta(t-\\tau)$ is $h(t-\\tau)$; so the response to $f(\\tau) \\delta(t-\\tau)d\\tau$ is\n",
    "## $$ f(\\tau) h(t-\\tau) d\\tau $$\n",
    " \n",
    "### Then, by linearity (aka superposition) the system response to the input signal $f(t)$ is\n",
    "## $$ x(t) = \\int_{0}^{t} f(\\tau) h(t-\\tau) d\\tau $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a844ed-4cf5-4f1a-a03c-8f3c1f13f521",
   "metadata": {},
   "source": [
    "## L11.7. Proof of convolution formula.\n",
    "\n",
    "### Laplace transform takes convolution to the ordinary product:\n",
    "## $$ f(t) * h(t) \\rightsquigarrow F(s) H(s) $$\n",
    " \n",
    "### This follows from what we have done above; but let's check it directly. For this we need to return to the definition of Laplace transform.\n",
    "## $$ \\begin{array} {rcl} \\displaystyle f(t) * h(t) & \\rightsquigarrow & \\displaystyle \\int_{0}^{\\infty} \\left(f(t) * h(t) \\right) e^{-st} dt \\\\ \\, & = & \\displaystyle \\int_{0}^{\\infty} \\left[ \\int_{0}^{t} f(\\tau) h(t-\\tau) d\\tau \\right] e^{-st} dt \\end{array} $$\n",
    " \n",
    "### To get the Laplace transforms of $f(t)$ and $h(t)$ involved, we should reverse the order of integration:\n",
    "## $$ \\cdots = \\int_{0}^{\\infty} \\left[ \\int_{\\tau}^{\\infty} f(\\tau) h(t-\\tau) e^{-st} dt \\right] d\\tau $$\n",
    " \n",
    "### The expression $h(t-\\tau)$ suggests that we change variables; say $u=t-\\tau$. In the inner integral, $\\tau$ is constant, so $du=dt$. The limits on $u$ are $\\tau$ less than the limits on $t$, so we have\n",
    "## $$ \\cdots = \\int_{0}^{\\infty} \\left[ \\int_{0}^{\\infty} f(\\tau) h(u) e^{-s(u+r)} du \\right] d\\tau $$\n",
    " \n",
    "### Now pull the factors depending only on $\\tau$ outside the integral over $u$, remembering that $e^{-s(u+\\tau)} = e^{-st}e^{-s\\tau}$:\n",
    "## $$ \\cdots = \\int_{0}^{\\infty} f(\\tau) e^{-s\\tau}\\left[ \\int_{0}^{\\infty} h(u) e^{-su} du \\right] d\\tau $$\n",
    " \n",
    "### This is indeed just the product of the integrals defining $F(s)$ and $H(s)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e936e19a-aebb-4e3b-b312-4d092457a6fb",
   "metadata": {},
   "source": [
    "## L11.8. Properties.\n",
    "\n",
    "### The convolution is a new kind of “***product***\" of two signals. It enjoys the following properties for functions $f(t), g(t)$ and constants $a, b$, .\n",
    "\n",
    "### - Bi-linearity:\n",
    "## $$ [a f(t) + b g(t)]* h(t) = a[f(t)*h(t)] + b [g(t)*h(t)] $$\n",
    " \n",
    "### and\n",
    "## $$ f(t) * [a g(t) + b h(t)] = a[f(t) * g(t)] + b[f(t) * h(t)] $$\n",
    " \n",
    "### - Associativity:\n",
    "## $$ [f(t)*g(t)] * h(t) = f(t) * [g(t) * h(t)] $$\n",
    " \n",
    "### - Commutativity:\n",
    "## $$ f(t) * h(t) = h(t) * f(t) $$\n",
    " \n",
    "### - Unit: The delta function serves as the unit for convolution:\n",
    "## $$ \\delta(t) * f(t) = f(t) = f(t) * \\delta(t) $$\n",
    " \n",
    "### These properties can be checked by direct manipulation of the convolution integral. But it's easier to check that they hold after application of Laplace transform, where they are obvious; in the frequency domain they are just the properties of the usual multiplication of functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca67bdd-98d5-435c-85be-b75f2fb030fa",
   "metadata": {},
   "source": [
    "## L11.9. Block diagrams: back to the time domain.\n",
    "\n",
    "### The formalism of the frequency domain lets us represent both systems and signals in the same language. A signal is represented by its Laplace transform. A system is represented by its transfer function, or, what is the same thing, the Laplace transform of its unit impulse response.\n",
    "\n",
    "### The convolution product allows us to do the same in the time domain. We have just seen that if you have an LTI system with system unit impulse response h(t), then a general input signal $f(t)$ produces $f(t)*h(t)$ as system response. So, working entirely in the time domain, we can write\n",
    "![img](img/sc01.png)\n",
    "\n",
    "### In particular we can take $f(t) = \\delta(t)$. Then by definition the output is $h(t)$; that is,\n",
    "## $$ \\delta(t) * h(t) = h(t) $$\n",
    " \n",
    "### How does a cascade work out?\n",
    "![img](img/sc02.png)\n",
    "\n",
    "### To determine the answer, we just need to determine the unit impulse response of the cascaded system. Since $\\delta(t)*g(t) = g(t)$,\n",
    "![img](img/sc03.png) \n",
    "\n",
    "### That is, the unit impulse response of the cascade is the convolution of the two constituent unit impulse responses:\n",
    "![img](img/sc04.png) \n",
    "\n",
    "### This perspective makes associativity obvious. Each of the 5 block diagrams below represent the same system. The first translates to $(f*g)*h$ and the last to $f*(g*h)$.\n",
    "![img](img/sc05.png)\n",
    "\n",
    "### But commutativity seems more surprising: if you feed signal $f(t)$ to a system with unit impulse response $g(t)$, the outcome is the same as if you were to feed $g(t)$ to a system with unit impulse response $f(t)$! Commutativity is one of the miraculous outcomes of the LTI hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5af2c0-dd23-4f83-8126-45bb31ddc2ea",
   "metadata": {},
   "source": [
    "## L11.10. Convolution and generalized functions.\n",
    "\n",
    "### The delta function $\\delta(t)$ serves as the unit for the convolution product. To accommodate the delta function in the convolution integral, we should refine it to read\n",
    "## $$ f(t) * h(t) = \\int_{0^-}^{t^+} f(\\tau) h(t-\\tau)d\\tau $$\n",
    " \n",
    "### Then, indeed,\n",
    "## $$ \\delta(t) * h(t) = \\int_{0^-}^{t^+} \\delta(\\tau) h(t-\\tau) d\\tau = \\left. h(t-\\tau)\\right|_{\\tau=0} = h(t) $$\n",
    " \n",
    "### More generally,\n",
    "## $$ \\delta(t-a) * h(t) = \\int_{0^-}^{t^+} \\delta(t-a) h(t-\\tau) d\\tau = \\left. h(t-\\tau) \\right|_{\\tau=a} = h(t-a) $$\n",
    " \n",
    "### – that is, convolving with $\\delta(t-a)$ (for $a\\geq 0$) delays a signal by $a$ units; it shifts the graph to the right by $a$ units. In particular,\n",
    "## $$ \\delta(t-a) * \\delta(t-b) = \\delta(t-(a+b)) $$\n",
    " \n",
    "### These formulas let us convolve generalized functions as well as piecewise continuous functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1440b691-78cb-4bc1-a8b3-36a1f7eb50fb",
   "metadata": {},
   "source": [
    "## L11.12. Motivation for convolution.\n",
    "\n",
    "### Let $f(t)$ and $g(t)$ be two functions with Laplace transforms\n",
    "## $$ \\begin{array} {rcl} f(t) & \\rightsquigarrow & F(s) \\\\ g(t) & \\rightsquigarrow & G(s) \\end{array} $$\n",
    "\n",
    "### A natural question one might ask is if there is a formula for the Laplace transform of $f(t)g(t)$ in terms of $F(s)$ and $G(s)$. No such formula exists. Instead, one can ask if the function $F(s)G(s)$ is the Laplace transform of a function that can be built out of $f(t)$ and $g(t)$. This is possible, and the answer is the convolution.\n",
    "\n",
    "### ***Definition 12.1***\n",
    "### The convolution of $f(t)$ and $g(t)$, written as $f(t)*g(t)$, is the function of $t$ whose Laplace transform is $F(s)G(s)$.\n",
    "\n",
    "### ***Power series motivation***\n",
    "### The power series\n",
    "## $$ F(x) = \\sum_{n=0}^{\\infty} a_n x^n $$\n",
    " \n",
    "### is the discrete analogue of the Laplace transform. You can see this by writing $a_n=a(n)$ as a function of $n$, and writing $x=e^{-s}$. Then we can think of\n",
    "## $$ F(x) = \\sum_{n=0}^{\\infty} a(n) e^{-sn} $$\n",
    " \n",
    "### as the discrete version of the Laplace transform of $a(n)$.\n",
    "\n",
    "### Write two power series\n",
    "## $$ \\begin{array} {rcl} F(x) & = & \\displaystyle \\sum_{n=0}^{\\infty} a_n x^n \\\\ G(x) & = & \\displaystyle \\sum_{n=0}^{\\infty} b_n x^n \\end{array} $$\n",
    "\n",
    "### Write the product as a power series\n",
    "## $$ F(x) G(x) = \\sum_{n=0}^{\\infty} c_n x^n $$\n",
    " \n",
    "### The question analogous to convolution in power series is to find the formula for $c_n$ in terms of the $a_i$'s and $b_j$'s.\n",
    "## $$ c_n = \\sum_{k}^{n} a_k b_{n-k} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a803dfaf-8854-4bd2-a230-20ee70093649",
   "metadata": {},
   "source": [
    "## L12.2. Reintroducing the Mascot.\n",
    "\n",
    "### A tuned mass damper is a system of coupled damped oscillators in which one oscillator is regarded as primary and the second as a control or secondary oscillator. If tuned properly the maximum amplitude of the primary oscillator in response to a periodic driving force will be lowered and much of the energy will be absorbed by the secondary oscillator.\n",
    "\n",
    "### This kind of system is used for example in tall buildings to limit the swaying of the building in the wind. People are sensitive to this swaying, so by adding a tuned mass damper the building sways less and the damper, which no one can feel, vibrates instead. Another application is to stabilize laboratory tables supporting experiments that are sensitive to vibrations.\n",
    "\n",
    "### The 18.03Lx mascot is an example of such a system. The figure below represents an idealized version of it.\n",
    "![img](img/mascot.png)\n",
    "\n",
    "### The first mass $m_1$ is attached on one side to a wall by a spring and damper and on the other side it is attached to a second mass $m_2$ by another spring and damper. The spring and damping constants $k_1, k_2, b_1, b_2$ are indicated on the figure. A force $f(t)$ pushes on the first mass. The absolute positions of the masses are given by $x_1$ and $x_2$, arranged so that the spring between them is relaxed when $x_1=x_2$ and the spring connecting the first mass to the wall is relaxed when $x_1=0$.\n",
    "\n",
    "### We will regard first mass as the building, or the table – it's being shaken by some force, and we wish to control the amplitude of its resulting oscillation – so the system response of interest is $x_1$. The second mass is presumably smaller, and the behavior of $x_2$ is of only secondary interest.\n",
    "\n",
    "### In this Lecture, we will work out the system function of this fairly complicated system. To accomplish this goal, we will watch it in action and record its system response. Finally, we match the resulting Bode plot in order to discover the pole/zero diagram of the system and hence information about the system parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3013ed-bb84-473c-90a7-16d44f6f7394",
   "metadata": {},
   "source": [
    "## L12.3. The differential equations.\n",
    "\n",
    "### Newton's law $f=ma$ and the usual assumptions about linear damping and spring force lead to the following differential equations governing the motion of the system.\n",
    "## $$ \\begin{array} {rrrrrclllll} m_1\\ddot{x}_1 & + & b_1\\dot{x}_1 & + & k_1 x_1 & - & b_2(\\dot{x}_2-\\dot{x}_1) & - & k_2(x_2-x_1) & = & f(t) \\\\ m_2\\ddot{x}_2 & + & & & & + & b_2(\\dot{x}_2-\\dot{x}_1) & + & k_2(x_2-x_1) & = & 0 \\end{array} $$\n",
    " \n",
    "### Let's rearrange these equations to put all the $x_1$'s on one side and all the $x_2$'s on the other:\n",
    "## $$ \\begin{array} {rcl} (m_1\\ddot{x}_1+b_1\\dot{x}_1+k_1 x_1)+(b_2\\dot{x}_1+k_2 x_1) & = & f(t) + b_2 \\dot{x}_2 + k_2 x_2 \\\\ m_2 \\ddot{x}_2 + b_2 \\dot{x}_2 + +k_2 x_2 & = & b_2 \\dot{x}_1 + k_2 x_1 \\end{array} $$\n",
    "\n",
    "### We can simplify the notation, and clarify the structure of these equations, by using operator notation. Define polynomials\n",
    "## $$ \\begin{array} {rcl} P_1(s) & = & m_1 s^2 + b_1 s + k_1 \\\\ P_2(s) & = & m_2 s^2 + b_2 s + k_2 \\\\ Q_2(s) & = & b_2 s + k_2 \\end{array} $$\n",
    "### Thus $P_1(s)$ is the characteristic polynomial of the first oscillator, $P_2(s)$ is the characteristic polynomial of the second oscillator, and $Q_2(s)$ is a first order polynomial reflecting the components connecting the two systems. Our system of equations becomes\n",
    "## $$ \\begin{array} {rcl} (P_1(D)+Q_2(D))x_1 & = & f(t) + Q_2(D) x_2 \\\\ P_2(D) x_2 & = & Q_2(D) x_1 \\end{array} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2d4915-a7bb-49d5-a6e4-97d6aff05af4",
   "metadata": {},
   "source": [
    "## L12.4. The system function.\n",
    "\n",
    "### When we transform this system to the frequency domain we get\n",
    "## $$ \\begin{array} {rcl} (P_1(s) + Q_2(s)) X_1(s) & = & F(s) + Q_2(s) X_2(s) \\\\ P_2(s) X_2(s) & = & Q_2(s) X_1(s) \\end{array} $$\n",
    "\n",
    "### (For simplicity, from now on we'll write $P_1, X_1$ etc instead of $P_1(s), X_1(s)$ etc.)\n",
    "\n",
    "### This is a pair of linear equations relating $X_1, X_2$ and $F$. We're interested in $X_1$, so let's begin by isolating $X_1$ on the left of the first equation:\n",
    "## $$ X_1 = \\frac{1}{P_1+Q_2} (F+Q_2 X_2) $$\n",
    "\n",
    "### According to the second equation,\n",
    "## $$ X_2 = \\frac{Q_2}{P_2} X_1 $$\n",
    "\n",
    "### Thus $X_1$ arises from summing $F$ with a multiple of $X_2$, and $X_2$ is in turn a multiple of $X_1$. We can represent this recursion directly with a closed loop block diagram:\n",
    "![img](img/sc11.png)\n",
    "\n",
    "### The bottom branch shows $\\displaystyle X_2 = \\frac{Q_2}{P_2} X_1$. This is then scaled by $Q_2$ and fed back into the top branch, which shows\n",
    "## $$ X_1 = \\frac{1}{P_1+Q_2}(F+Q_2 X_2) $$\n",
    " \n",
    "### These are exactly the equations above.\n",
    "\n",
    "### Altogether the bottom part of the loop multiplies $X_1$ by $\\displaystyle \\frac{Q_2^2}{P_2}$ and feeds this back into the top branch. Notice that this feedback is entirely determined by the parameters of the secondary oscillator. This acts like a \"feedback control system\", but strictly speaking it is not one. Roughly, such control systems are characterized by the following feedback loop,\n",
    "![img](img/sc12.png)\n",
    "\n",
    "### with the requirement that the “plant\" parameters on the top branch are independent of the “control\" parameters on the bottom branch.\n",
    "\n",
    "### In the tuned mass damper, we are trying to moderate the oscillations of the primary mass by tuning the parameters in the secondary system. But the secondary system parameters in $Q_2$ enter into the system function along the top branch. However, in practice the secondary mass damping term  is very small, and if we can make the spring constant $k_2$ small relative to the quantities occurring in the primary system, then the model is essentially an example of feedback control.\n",
    "\n",
    "### Let's find the transfer function. We use the equation for $X_2$ to eliminate the $X-2$ from the equation for $X_1$:\n",
    "## $$ \\begin{array} {rcl} X_2 & = & \\displaystyle \\frac{Q_2}{P_2}X_1 \\\\ X_1 & = & \\displaystyle \\frac{1}{P_1+Q_2}\\left( F+Q_2 \\frac{Q_2}{P_2} X_1 \\right) \\\\ \\, & = & \\displaystyle \\frac{1}{P_1+Q_2} \\left( F + \\frac{Q_2^2}{P_2} X_1 \\right) \\\\ \\displaystyle X_1\\left(1 - \\frac{Q_2^2}{(P_1+Q_2)P_2}\\right) & = & \\displaystyle \\frac{1}{P_1+Q_2} F \\\\ \\displaystyle X_1 \\left( \\frac{(P_1+Q_2)P_2 - Q_2^2}{(P-1+Q_2)P_2} \\right) & = & \\displaystyle  \\frac{1}{P_1+Q_2} F \\\\ X_1 & = & \\displaystyle \\frac{P_2}{P_1P_2 +Q_2(P_2-Q_2)}F \\end{array} $$\n",
    "\n",
    "### Then using the fact that $P_2-Q_2 = m_2 s^2$, we find\n",
    "## $$ X_1 = \\frac{P_2}{P_1P_2 + m_2 s^2 Q_2} $$\n",
    " \n",
    "### The transfer function is thus\n",
    "## $$ H_1(s) = \\frac{P_2}{P_1P_2+m_2 s^2 Q_2} $$\n",
    " \n",
    "### ***Question***: Obtain this transfer function using Black's formula.\n",
    "\n",
    "### ***Check your answer***.\n",
    "### We essentially re-derived Black's formula in finding the transfer function above. Still, it is worth seeing that Black's formula would have covered this situation without having to reiterate the logic.\n",
    "\n",
    "### For the following closed loop system with positive feedback\n",
    "![img](img/sc13.png)\n",
    "\n",
    "### Black's formula says the closed loop transfer function is $\\displaystyle \\frac{G(s)}{1-K(s)G(s)}$. In our case,\n",
    "## $$ G(s) = \\frac{1}{P_1+Q_2}\\quad \\text{and}\\quad K(s) = \\frac{Q_2^2}{P_2} $$\n",
    " \n",
    "### Putting these into Black's formula gives the same formula for the transfer function that we found above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd178d66-30fa-4a32-b10a-9e46d548c5ff",
   "metadata": {},
   "source": [
    "## L12.7. Interpretation on Mascot system behavior\n",
    "\n",
    "### We will try to understand various behaviors of the Mascot system. Recall the system\n",
    "![img](img/mascot.png) \n",
    "\n",
    "### and its system function\n",
    "## $$ H_1 (s) = \\frac{P_2}{P_1P_2 + m_2 s^2 Q_2} $$\n",
    " \n",
    "### with\n",
    "## $$ \\begin{array} {rcl} P_1(s) & = & m_1 s^2 + b_1 s + k1 \\\\ P_2(s) & = & m_2 s^2 + b_2 s + k_2 \\\\ Q_2(s) & = & b_2 s + k_2 \\end{array} $$\n",
    "\n",
    "### This formula contains several interesting pieces of information.\n",
    "\n",
    "### 1. When the fourth order system was driven at a certain frequency, the mass seemed to just stop. The force continued to be applied to it, and the secondary mass was vibrating rapidly, but the shaft itself was completely stationary. What was happening? The ***gain*** at that frequency – say $\\omega$ – was apparently zero. This only happens when $H_1(i\\omega) = 0$.\n",
    "\n",
    "### From the formula for $H_1$, you see that the zeros of the transfer function for this closed loop system occur precisely at the poles of the transfer function for the secondary oscillator – namely, at the roots of the characteristic polynomial $P_2(s) = m_2 s^2 + b_2 s + k_2$.\n",
    "\n",
    "### Suppose that the secondary oscillator is lightly damped; in fact, for simplicity, suppose that it is ***undamped***: $b_2=0$. Then these roots are $\\pm i\\omega$, where $\\displaystyle \\omega_2 = \\sqrt{\\frac{k_2}{m_2}}$ is the natural frequency of the secondary oscillator. That is,\n",
    "## $$ \\omega = \\omega_2 $$\n",
    " \n",
    "### In the real situation of a tuned mass damper, the main natural frequency of a building might be, say, $\\omega_n$. The trick is then to adjust the parameters $m_2$ and $k_2$ of the secondary oscillator so that $\\omega_2 = \\omega_n$, because then the mass in the primary oscillator will be ***stationary***. This is ideal!\n",
    "\n",
    "### In the real situation of a tuned mass damper, the practical resonant frequency of a building might be, say, $\\omega_r$. This is the input frequency that would cause the largest oscillation. The trick to damping out these oscillations is then to adjust the parameters $m_2$ and $k_2$ of the secondary oscillator so that $\\omega_2 = \\omega_r$, i.e. we tune the system so the zero of $P_2$ is at the resonant frequency for $P_1$.\n",
    "\n",
    "### A peculiar feature of this result is that it appears that it can be made to function no matter what the secondary mass is.\n",
    "\n",
    "### ***Question***:\n",
    "### What's the downside to using very small mass for the secondary oscillator? Why do actual tuned mass dampers weigh hundreds of tons?\n",
    "\n",
    "### ***Answer***\n",
    "### We'll continue with the approximation that $b_2 = 0$, and think about the angular frequency of interest, $\\displaystyle \\omega_r = \\sqrt{\\frac{k_2}{m_2}}$. Then $P_2(i \\omega_r) = 0$, so\n",
    "## $$ H_2(s) = \\frac{Q_2}{P_1 P_2 + m_2 s^2 Q_2} $$\n",
    " \n",
    "### evaluates at $s = i \\omega_r$ to\n",
    "## $$ H_2(i\\omega_r) = \\frac{Q_2(i\\omega_r)}{m_2 (i\\omega_r)^2 Q_2(i\\omega_r)} = -\\frac{1}{m_2 \\omega_r^2} $$\n",
    " \n",
    "### The fact that this is real and negative indicates that at this resonant point the secondary mass is oscillating in “anti-phase\" with a phase lag of 180 degrees relative to the input signal. This makes sense!\n",
    "\n",
    "### The expression for $H_2(i\\omega_r)$ also shows that if $m_2$ is small then the gain $\\displaystyle |H_2(i\\omega_r)| = \\frac{1}{m_2 \\omega_r^2}$ is large. So large that the amplitude of oscillation of the secondary mass will send it right through the wall of the building!\n",
    "\n",
    "### 2. The transients of this system are of the form $e^{rt}$ where $r$ is a pole of $H_1(s)$ (assuming all these poles are simple). For almost all choices of system parameters, the roots of the numerator will differ from the roots of the denominator. (Actually, you can check that they definitely differ as long as $m_2\\neq 0$ and $k_2\\neq 0$.) In that case, the poles of $H_1(s)$ are precisely the roots of the denominator, $P_1(s)P_2(s)+m_2 s^2 Q_2(s)$. This is a fourth degree polynomial (as long as $m_1 \\neq 0$ as well!) so there are four independent transients. This makes sense, since there are four degrees of freedom in choosing initial conditions: you can set the position and the velocity of each of the two masses. This is a fourth order system.\n",
    "\n",
    "### 3. It is always interesting to check out what happens for large frequencies. When $|s|$ is very large\n",
    "## $$ H_1(s) \\approx \\frac{m_2 s^2}{m_1 s^2 m_2 s^2} = \\frac{1}{m_1} s^{-2} $$\n",
    " \n",
    "### Three things to note:\n",
    "\n",
    "### - The gain at high frequency $\\omega$ is proportional to $\\omega^{-2}$. This reflects the fact that the degree of the denominator in $H_1(s)$ is the degree of the numerator plus 2.\n",
    "### - The phase lag is about $180^\\circ$, because with $s=i\\omega$, $s^{-2}$ is real and negative. The mass is moving against the impressed force.\n",
    "### - At high frequencies the system is approximately the same as that of the primary mass without the secondary oscillator attached."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9b6ab8-1215-41b3-b26f-1b471f9687c1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
